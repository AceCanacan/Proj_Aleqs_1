{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV data into a DataFrame\n",
    "df = pd.read_csv('../data/cases_w_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1:\n",
      "Link: https://elibrary.judiciary.gov.ph/assets/dtSearch/dtSearch_system_files/dtisapi6.dll?cmd=getdoc&DocId=2057&Index=%2a4aeb4dbdcceeda9b59b85ae3fb22cec0&HitCount=8&hits=7a+7d+e0+183+1fc+442+486+4d1+&SearchForm=C%3a%5celibrev2%5csearch%5csearch%5fform\n",
      "Case Title: [ G.R. No. 6717. October 19, 1911 ] THE UNITED STATES, PLAINTIFF AND APPELLEE, VS. FAUSTINO MESINA, DEFENDANT AND APPELLANT. D E C I S I O N TORRES, J.:\n",
      "Content (first 100 characters): 21 Phil. 615 [ G.R. No. 6717. October 19, 1911 ] THE UNITED STATES, PLAINTIFF AND APPELLEE, VS. FAUS...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Node 2:\n",
      "Link: https://elibrary.judiciary.gov.ph/assets/dtSearch/dtSearch_system_files/dtisapi6.dll?cmd=getdoc&DocId=1140&Index=%2a4aeb4dbdcceeda9b59b85ae3fb22cec0&HitCount=17&hits=14e+2f9+371+372+583+68a+70b+70c+7b4+7b5+7d9+85e+9c1+9d2+11d6+122c+1618+&SearchForm=C%3a%5celibrev2%5csearch%5csearch%5fform\n",
      "Case Title: [ G.R. No. 6923. September 12, 1912 ] THE UNITED STATES, PLAINTIFF AND APPELLEE, VS. VALENTIN BERNABE, DEFENDANT AND APPELLANT. D E C I S I O N TORRES, J.:\n",
      "Content (first 100 characters): 23 Phil. 154 [ G.R. No. 6923. September 12, 1912 ] THE UNITED STATES, PLAINTIFF AND APPELLEE, VS. VA...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Node 3:\n",
      "Link: https://elibrary.judiciary.gov.ph/assets/dtSearch/dtSearch_system_files/dtisapi6.dll?cmd=getdoc&DocId=993&Index=%2a4aeb4dbdcceeda9b59b85ae3fb22cec0&HitCount=10&hits=67c+6c3+6c5+757+7f0+8f8+983+ae4+b5b+dde+&SearchForm=C%3a%5celibrev2%5csearch%5csearch%5fform\n",
      "Case Title: [ G.R. No. 1237. September 30, 1903 ] THE UNITED STATES, COMPLAINANT AND APPELLEE, VS. LEONARDO GUINACARAN ET AL., DEFENDANTS AND APPELLANTS. D E C I S I O N TORRES, J.:\n",
      "Content (first 100 characters): 2 Phil. 551 [ G.R. No. 1237. September 30, 1903 ] THE UNITED STATES, COMPLAINANT AND APPELLEE, VS. L...\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_node(row) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a node for each row of the DataFrame. \n",
    "    Each node contains the content, link, and case title of the document.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'content': row['content'],\n",
    "        'link': row['links'],  # Assuming the column name in the CSV is 'links'z\n",
    "        'case_title': row['case_title']\n",
    "    }\n",
    "\n",
    "# Apply the function to each row of the DataFrame to create nodes\n",
    "df['node'] = df.apply(create_node, axis=1)\n",
    "\n",
    "# Display the first few nodes to inspect their structure and content\n",
    "for index, row in df.head(3).iterrows():\n",
    "    node = row['node']\n",
    "    print(f\"Node {index+1}:\")\n",
    "    print(f\"Link: {node['link']}\")\n",
    "    print(f\"Case Title: {node['case_title']}\")\n",
    "    print(f\"Content (first 100 characters): {node['content'][:100]}...\")  # Show a snippet of the content for brevity\n",
    "    print(\"------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Embeddings.create() got an unexpected keyword argument 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# Generate embeddings for the content chunks of the first document\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[1;32m     40\u001b[0m     \u001b[39m# Corrected from node.content to node.text\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     embedding \u001b[39m=\u001b[39m get_embedding(node\u001b[39m.\u001b[39;49mtext)  \u001b[39m# Use 'text' instead of 'content'\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     embeddings\u001b[39m.\u001b[39mappend(embedding)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, engine)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embedding\u001b[39m(text, engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-embedding-ada-002\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49membeddings\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     16\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m     17\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m[text]\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[39m# Extract and return the embedding vector\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m response[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Embeddings.create() got an unexpected keyword argument 'engine'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=[text]\n",
    "    )\n",
    "    # Extract and return the embedding vector\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "# Function to create nodes from the DataFrame has been provided by the user\n",
    "\n",
    "# Assume df is your DataFrame with the case documents\n",
    "# Apply the function to create nodes\n",
    "df['node'] = df.apply(create_node, axis=1)\n",
    "\n",
    "# Initialize the node parser\n",
    "node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "# For demonstration, we will only process the first node's content\n",
    "document = Document(text=df.iloc[0]['node']['content'])\n",
    "nodes = node_parser.get_nodes_from_documents([document], show_progress=False)\n",
    "\n",
    "# Initialize a list to hold embeddings for the chunks of the first document\n",
    "embeddings = []\n",
    "\n",
    "# Generate embeddings for the content chunks of the first document\n",
    "for node in nodes:\n",
    "    # Corrected from node.content to node.text\n",
    "    embedding = get_embedding(node.text)  # Use 'text' instead of 'content'\n",
    "    embeddings.append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(openai.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
